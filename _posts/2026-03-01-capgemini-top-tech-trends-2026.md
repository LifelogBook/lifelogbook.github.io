---
layout: single
classes: wide
title: "2026 주요 기술 트렌드 — Capgemini"
categories: Report
tags: [AI, capgemini, cloud, technology-trends, english-study, agentic-ai, sovereignty, intelligent-ops]
toc: true
toc_sticky: true
toc_label: "목차"
toc_icon: "fas fa-file-alt"
author_profile: false
sidebar:
    nav: "counts"
---

> **원문:** Capgemini — *Top Tech Trends of 2026* (2026, 32pp.)
> **분류:** 기술 트렌드 보고서 \| **저자:** Pascal Brier, Group Chief Innovation Officer, Capgemini

---

## 한글 번역

### 서론

2026년은 AI·클라우드·데이터·자동화 분야에서 수년간의 비범한 가속을 거쳐, 향후 10년을 뒷받침할 **기반을 강화·업그레이드·재구축하는 전환점**으로 부상하고 있습니다.

산업 전반에 걸쳐 경영진들은 단편적인 파일럿 프로젝트나 느슨하게 연결된 디지털 이니셔티브만으로는 더 이상 진전을 이룰 수 없다는 사실을 인식하고 있습니다. 실험적 AI의 시대는 서서히 막을 내리고, 신뢰할 수 있는 데이터·명확한 거버넌스·확장 가능한 아키텍처·안전성과 신뢰성을 위해 설계된 시스템이라는 **탄탄한 AI 기반**의 필요성으로 이동하고 있습니다. 분리된 모델에서 통합된 전사적 인텔리전스로 전환할 수 있는 조직이 지속적인 가치를 창출하는 시대가 열리고 있습니다.

동시에, 글로벌 환경은 기업들로 하여금 훨씬 더 깊은 수준에서 회복 탄력성과 비즈니스 연속성을 재고하도록 강제하고 있습니다. 반도체와 클라우드 서비스부터 AI 모델과 컴퓨트 인프라에 이르기까지 핵심 기술에 대한 의존도가 높아지면서, 이는 순수한 기술적 선택이 아닌 **전략적 리스크 요인**으로 부상했습니다. 이러한 흐름은 이중의 움직임을 촉발하고 있습니다: 혼란을 견딜 수 있는 아키텍처를 향한 새로운 추진력, 그리고 가장 중요한 기술 레이어에 대한 통제권 강화를 위한 탐색입니다.

클라우드 전략 역시 이에 맞게 진화하고 있습니다. 하이브리드·멀티클라우드·소버린 옵션들이 예외적 선택이 아닌, 연속성을 확보하고 집중 리스크를 줄이며 데이터와 운영을 보호하기 위한 **표준 메커니즘**으로 부상하고 있습니다. 주권(Sovereignty)이 이러한 전환의 일부이지만, 근본적인 주제는 더 광범위합니다: 조직들은 특정 의존성이 운영 능력을 침해하지 않도록 하면서도 개방적이고, 확장 가능하며, 전 세계적으로 연결된 상태를 유지하도록 기반을 재설계하고 있습니다.

2026년의 주요 기술 트렌드는 이러한 구조적 재건을 향한 전환을 반영하며, 하나의 핵심 메시지를 전달합니다: **2026년의 기술 리더십은 더 이상 실험이 아니라, 혁신에서 진정한 가치를 추출할 수 있게 하는 내구성 있는 기반을 구축하는 것**에 관한 것입니다.

모든 주요 기술 전환이 보여주듯, 장기적 우위를 결정하는 것은 개별 도구의 참신함이 아니라, 이 기반들의 강건함입니다. 본 보고서는 이 기반들이 재건되는 시점에 비즈니스 및 기술 리더들이 올바른 전략적 선택을 내릴 수 있도록 돕는 것을 목표로 합니다.

*— Pascal Brier, Group Chief Innovation Officer, Member of the Group Executive Committee, Capgemini*

---

### 지난 2년간의 주요 기술 트렌드 회고

<table style="width:100%; border-collapse:collapse; margin:1.5rem 0; font-size:0.93rem;">
  <thead>
    <tr>
      <th style="background:#0070AD; color:#fff; padding:12px 18px; text-align:left; width:50%;">2025년 트렌드</th>
      <th style="background:#1B2845; color:#fff; padding:12px 18px; text-align:left; width:50%;">2024년 트렌드</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding:12px 18px; border-bottom:1px solid #b8d8ef; background:#EBF5FB;"><strong>생성형 AI:</strong> 코파일럿에서 추론 AI 에이전트로</td>
      <td style="padding:12px 18px; border-bottom:1px solid #2e3f62; background:#1B2845; color:#dce6f5;"><strong>생성형 AI:</strong> 소형 모델이 새로운 빅트렌드</td>
    </tr>
    <tr>
      <td style="padding:12px 18px; border-bottom:1px solid #b8d8ef; background:#EBF5FB;"><strong>사이버보안:</strong> 새로운 방어, 새로운 위협</td>
      <td style="padding:12px 18px; border-bottom:1px solid #2e3f62; background:#1B2845; color:#dce6f5;"><strong>양자 기술:</strong> 사이버와 양자의 만남</td>
    </tr>
    <tr>
      <td style="padding:12px 18px; border-bottom:1px solid #b8d8ef; background:#EBF5FB;"><strong>AI 기반 로보틱스:</strong> 인간과 기계의 경계를 흐리다</td>
      <td style="padding:12px 18px; border-bottom:1px solid #2e3f62; background:#1B2845; color:#dce6f5;"><strong>반도체:</strong> 무어의 법칙은 죽지 않았다, 변하고 있을 뿐</td>
    </tr>
    <tr>
      <td style="padding:12px 18px; border-bottom:1px solid #b8d8ef; background:#EBF5FB;"><strong>원자력:</strong> AI 수요가 이끄는 클린테크 어젠다</td>
      <td style="padding:12px 18px; border-bottom:1px solid #2e3f62; background:#1B2845; color:#dce6f5;"><strong>배터리:</strong> 새로운 화학의 힘</td>
    </tr>
    <tr>
      <td style="padding:12px 18px; background:#EBF5FB;"><strong>차세대 공급망:</strong> 민첩하고, 친환경적이며, AI 보조적</td>
      <td style="padding:12px 18px; background:#1B2845; color:#dce6f5;"><strong>우주 기술:</strong> 우주에서 지구의 문제를 해결하다</td>
    </tr>
  </tbody>
</table>

---

### Trend 1. AI의 진실의 해

전례 없는 투자와 실험의 시기를 거쳐, AI는 이 시대의 핵심 기술로 자리매김했습니다. 그러나 투자의 속도는 조직들이 AI를 대규모로 구축하고 측정 가능한 가치를 추출할 수 있는 속도를 앞질렀습니다. 많은 기업들은 현재 통합되지 않고, 활용이 부족하거나, 실질적인 비즈니스 성과와 단절된 정교한 모델·에이전트·프로토타입을 보유하고 있습니다. 이러한 간극은 어느 정도의 AI 과대선전(hype)에 대한 회의감을 낳았습니다.

하지만 소음 아래에서 더욱 본질적인 변화가 모습을 드러내고 있습니다. AI의 구조적 토대가 성숙하고 있는 것입니다. 파일럿을 넘어선 조직들은 이미 실질적인 결과를 목격하고 있으며, 얼리 어답터들은 핵심 디지털 및 소프트웨어 운영 전반에 걸쳐 **7~18%의 생산성 향상**을 보고하고 있습니다. 중요한 것은, 이 성과가 단순히 효율성으로 흡수되지 않는다는 점입니다: 절약된 시간의 절반은 새로운 기능 개발에 재투자되고, 거의 같은 수의 조직이 이를 인력 역량 강화에 활용합니다. 이는 실험에서 **가치의 복리(value compounding)**로의 전환을 의미합니다.

동시에 AI 자체도 형태와 기능에서 진화하고 있습니다. 대형 모델들은 더욱 모듈화되고, 에이전트들은 단순 도구에서 워크플로우 오케스트레이터로 이동하며, AI는 주변부 실험에서 기업 핵심부로의 심층 통합으로 전환하고 있습니다. 현재 소프트웨어 인력의 약 **46%가 생성형 AI 도구**를 사용하고 있으며, 2026년까지 그 수치는 **85%**에 달할 것으로 예상됩니다. 초기 채택에서 **기본 역량(default capability)**으로의 이동입니다.

바로 이 이유로 2026년이 AI의 진실의 해로 떠오릅니다. 단기적 과대선전은 사라지지만, 남는 것은 운영 가치·기업 아키텍처·지속적 생산성에 점점 더 기반을 둔 생태계입니다. 차별화는 더 이상 빠르게 상품화되는 모델 자체에서 나오지 않고, 아키텍처·통합·오케스트레이션, 그리고 AI를 내구성 있고 복리적인 비즈니스 가치로 전환하는 능력에서 나옵니다. 성급하게 조립된 "장난감 에이전트(toy agents)"는 실망을 새롭게 할 위험이 있습니다.

**왜 중요한가**

수년간의 과대선전과 단편적 파일럿을 거쳐, AI는 더 이상 '혁신 극장(innovation theater)'이 될 수 없습니다. 투자는 가치 전달을 앞질렀고, 2026년은 조직들이 개념 증명(proof-of-concept)에서 **영향 증명(proof-of-impact)**으로 이동해야 하는 시점입니다. AI의 다음 물결은 특정 도구나 모델 출시에 관한 것이 아닙니다. 운영·프로세스·사회 전반에 인텔리전스를 내재화하는 것입니다. 성공하는 리더들은 규모에서 측정 가능한 성과를 제공하는 데 필요한 역량·거버넌스·인간-AI 협력을 구축하며, 뒤따를 더 큰 규모의 전환을 위한 기반을 마련할 것입니다.

**주목할 사항**

조직들은 실험적 AI 에이전트에서 실제 기업 아키텍처 내에서 작동하도록 구축된 **프로덕션 수준의 에이전틱 시스템(production-grade agentic systems)**으로 전환하고 있습니다. 초기 개념 증명은 각각 정의된 역할·평가 루프·거버넌스 통제를 갖춘 여러 전문 에이전트를 조율하는 강력한 오케스트레이션 프레임워크로 대체됩니다. 범용 LLM이 상품화됨에 따라, 기업들은 금융·의료·소매·산업 운영에 맞춤화된 소형 파인튜닝 모델을 우선시합니다. 구체적인 ROI를 입증하라는 압력은 **AI 관찰가능성·평가·가치 측정**에 대한 투자를 가속화합니다. 마지막으로 **AI 강화 엔지니어링 및 운영**의 급속한 채택은 AI가 소프트웨어 개발 라이프사이클과 핵심 비즈니스 워크플로우 전반에 구조적 역량으로 내재화되고 있음을 의미합니다.

> *"생성형 AI는 전례 없는 수준의 투자와 관심을 끌었습니다. 2026년으로 접어들면서, 대화는 가치 창출 쪽으로 결정적으로 이동하고 있습니다 — 실험을 넘어 측정 가능한 비즈니스 임팩트로."*
>
> **— Mark Roberts**, Head of AI Futures Lab, Capgemini

---

### Trend 2. AI가 소프트웨어를 잠식한다

20년이 넘는 시간 동안 소프트웨어는 디지털 전환을 이끌어왔습니다. "소프트웨어가 세상을 먹었다"는 시대가 지나고, 이제 우리는 **"AI가 소프트웨어 자체를 잠식하기 시작하는"** 새로운 단계에 진입하고 있습니다. 코드 완성·자동화 테스트·프롬프트 기반 생성 등 고립된 AI 도구로 시작된 것이 이제 인간과 AI가 지속적으로 구상·설계·구축·리팩토링을 함께 수행하는 **근본적으로 새로운 소프트웨어 개발 패러다임**으로 진화했습니다.

AI 네이티브 개발은 더 이상 실험적이지 않습니다. 연간 수익 200억 달러 이상의 기업 중 **3/4이 이미 소프트웨어 엔지니어링을 위한 생성형 AI를 시범·확대 적용**했습니다. 기업들은 AI 지원 코딩을 넘어 완전 자율적인 소프트웨어 개발 생태계로 이동하고 있습니다: 자기 주도형 테스트 프레임워크·지능형 코드 생성 에이전트·지속적 자동 리팩토링 엔진·에이전틱 빌드-릴리즈 시스템이 배포됩니다. 그 영향은 혁신적입니다: 배포 주기 가속화, 기술 부채의 조기 해결, 그리고 개발자들은 수동 코드 작성에서 의도를 표현하고 지능형 파이프라인을 오케스트레이션하는 방식으로 전환합니다.

2026년에는 이 전환이 구조적으로 자리를 잡습니다. 개발자들은 점점 더 자연어나 고수준 사양으로 결과를 묘사합니다. AI가 설계를 생성하고, 구현하고, 테스트하고, 보안 처리하고, 최적화하고, 통합하고, 요구사항이 변화함에 따라 지속적으로 리팩토링합니다. AI가 조립한 컴포넌트가 거의 실시간으로 적응하고 소프트웨어가 정적 자산이 아닌 **진화하는 서비스**가 되는 새로운 모델이 등장합니다.

이 시점에서 전통적인 애플리케이션의 개념은 사라지기 시작합니다. 사용자는 목표를 표현하고, AI 에이전트는 동적으로 기반 로직을 조합·실행·유지합니다. 가시적인 앱 레이어는 축소되고, 그 뒤에서는 조합 가능한 AI 서비스가 자율적으로 진화하며 새로운 조건에 스스로 적응합니다. AI 생성 코드는 강력하지만 절대 무결하지 않으며, 거버넌스·검증·아키텍처 감독의 중요성이 그 어느 때보다 높아집니다.

**왜 중요한가**

이 전환은 기술적일 뿐만 아니라 전략적입니다. 에이전틱 파이프라인이 소프트웨어를 지속적으로 생성·테스트·리팩토링할 수 있어 QA 주기가 단축되고 거의 실시간 적응이 가능해집니다. 또한 AI 생성 소프트웨어는 디지털 주권에 새로운 옵션을 열어줍니다. 대규모 표준화 SaaS 플랫폼 의존에서 벗어나, 전략적 통제·규제 제약·데이터 현지화가 중요한 곳에서 코드베이스와 데이터 흐름을 직접 조직이 통제하는 맞춤 시스템이 실행 가능한 선택이 됩니다. 나아가 루틴 소프트웨어 개발 업무의 자동화가 엔지니어들의 역량을 아키텍처·제품 로직·거버넌스 등 고부가가치 업무로 전환시킵니다.

**주목할 사항**

기업들은 코드를 지속적으로 생성·테스트·보안처리·리팩토링하는 **에이전틱 빌드 시스템**을 배포하기 시작합니다. 이는 단순 코드 보조를 훨씬 넘어서 의도를 프로덕션 코드로 변환하는 완전한 오케스트레이션 엔진으로 기능합니다. **자율 품질 보증 및 신뢰성 파이프라인**의 급격한 발전도 눈에 띕니다. AI가 가능하게 하는 속도에서 수동 QA는 비실용적이 되므로, 이 파이프라인이 신뢰할 수 있는 AI 생성 소프트웨어의 근간을 형성합니다. AI에 의해 자동 조립되는 **동적·조합 가능 서비스**의 부상, 그리고 평가 프레임워크·행동 모니터링·계보 추적·아키텍처 가드레일을 갖춘 **AI 거버넌스 개발 환경**이 필수적이 됩니다.

> *"소프트웨어 창조의 근본이 다시 쓰이고 있습니다. 우리는 경쟁 우위가 비용·주권·사이버보안·데이터 프라이버시에 대한 깊은 통제에 달린, AI 기반 소프트웨어 재구축의 시대에 접어들고 있습니다."*
>
> **— Sudhir Pai**, Deputy Group CTO, Capgemini

---

### Trend 3. 지능형 운영의 부상

ERP 현대화·클라우드 마이그레이션·프로세스 자동화를 수년간 거쳐, 기업들은 이제 새로운 시대로 진입하고 있습니다. **운영 핵심이 설계에 의해 지능화되는 시대**입니다. AI는 더 이상 덧붙여지는 것이 아니라, 비즈니스 프로세스를 선형적이고 미리 정의된 순서에서 지속적 최적화가 가능한 살아있는 시스템으로 변환하는 완전한 재설계를 가능하게 합니다.

2025년, 운영 부문의 AI 에이전트 사용률은 **21%로 두 배 이상 증가**했습니다(2024년 10%에서). 이 전환의 중심에는 새로운 종류의 기업 핵심이 있습니다: 플랫폼·AI 에이전트·인간이 실시간으로 협력하여 민첩하고 탄력적인 운영을 유지하면서 효율성과 비즈니스 가치를 제공하는, 데이터로 구동되는 동적·모듈형 핵심입니다. 2028년까지 **가트너는 기업 워크플로우의 약 40%가 AI 에이전트에 의해 자동화되거나 보완될 것**으로 예상합니다.

세 가지 구조적 전환이 이 이동을 정의합니다.

**① 지능형 프로세스의 재상상** — AI 우선 프로세스들이 RPA·생성형 AI·에이전틱 AI를 결합한 기술로 하이퍼 자동화됩니다. 조직의 **82%가 2027년까지 AI 에이전트를 통합할 계획**이며, 임원의 **85%가 향후 3~5년 내에 에이전트가 하나 이상의 비즈니스 프로세스를 자율적으로 처리할 것으로 기대**합니다.

**② 가치 사슬 오케스트레이션** — 조직들은 고립된 프로세스 최적화에서 전체 가치 사슬 오케스트레이션으로 이동합니다. 사일로를 허물고, 핸드오프 마찰을 없애며, 기능들을 통합된 가치 흐름으로 연결하는 원활한 엔드-투-엔드 운영을 만들어냅니다.

**③ 인간-AI 공동 운영(Human-AI co-steering)** — AI가 제안하고 실행하는 동안, 인간은 감독하고, 결과를 검증하며, 판단을 적용합니다. 이 파트너십은 기계의 속도와 인간의 통찰력을 결합하여 실행을 가속화하면서 안전성·윤리적 가드레일·신뢰를 보호합니다.

**왜 중요한가**

운영은 모든 조직의 심장박동으로, 데이터가 풍부하고 반복적이며 비즈니스 성과와 깊이 연결되어 AI에 가장 강력한 사용 사례 중 하나입니다. 지능형 운영은 비용 절감을 넘어 기업이 비즈니스 가치를 창출하는 방식을 재정의합니다. AI가 운영 핵심에 내재화되면, 기업들은 변화를 예측하고, 실시간으로 적응하며, 혼란을 이점으로 전환하는 민첩성을 얻게 됩니다. AI가 진정한 공동 운영자가 되는 순간입니다.

**주목할 사항**

2025년, 에이전틱 AI 프로젝트는 주로 파일럿 이니셔티브를 통한 실험에 의해 **48% 급증**했습니다. 2026년에는 더 많은 조직이 파일럿에서 첫 번째 프로덕션 수준으로 이동하고, 초점이 비용 절감에서 가치 창출로 진화할 것으로 예상됩니다. 핵심 지표는 레거시 워크플로우를 AI 지원 방식으로 직접 대체하려는 의도의 증가입니다. 이것은 기존 프로세스에 자동화를 덧대는 것이 아니라 **처음부터 운영을 재설계하는(redesigning from the ground up)** 것입니다. 공급망·재무·조달·고객 운영이 하나의 오케스트레이션된 시스템으로 운영되는 **연결된 운영(connected operations)**의 부상, 그리고 운영 지휘 센터에서 인간-AI 공동 운영이 더욱 공식화되고 전략적으로 자리잡고 있다는 신호도 명확합니다.

> *"운영은 더 이상 한 번 최적화하고 시간이 지남에 따라 유지하는 정적 시스템이 아닙니다. 그것들은 지능적이고 적응적인 핵심으로 변모하고 있습니다 — AI가 프로세스에 내재화되고 인간이 지속적으로 학습하고 진화하는 시스템을 공동 운영하는."*
>
> **— Manuel Sevilla**, CTInO, Capgemini Business Services

---

### Trend 4. Cloud 3.0 — 모든 형태의 클라우드

클라우드는 다음 진화 단계에 진입하고 있습니다. 마이그레이션·현대화·비용 최적화에 집중한 10년을 지나, 이제 클라우드는 **AI 및 AI 지원 애플리케이션의 실행 백본**이 되고 있습니다. 이 전환은 규모에서 반영됩니다: 퍼블릭 클라우드 지출은 **2025년 7,230억 달러에서 2029년 1조 4,700억 달러로 거의 두 배**로 증가할 것으로 예상되며, 생성형 AI는 2020년대 말까지 그 지출의 **10~15%**를 차지할 것으로 전망됩니다. 클라우드 가치는 더 이상 탄력성만으로 정의되지 않고, AI 집약적인 항상 켜진 워크로드를 지원하는 능력으로 정의됩니다.

그러나 AI는 클래식 퍼블릭 클라우드 아키텍처만으로는 확장될 수 없습니다. 독점 데이터에서 모델을 파인튜닝하고, 데이터 민감성을 통제하고, 규제 제약을 충족하며, 저지연 추론을 제공해야 하는 필요성이 조직들을 하이브리드·프라이빗·멀티클라우드·소버린 클라우드 아키텍처로 이끌고 있습니다. 예외가 아닌 새로운 표준으로서 말입니다. 특히 에이전틱 시스템은 클라우드와 엣지가 단일 지능형 패브릭으로 운영되는 확장 가능하고 분산된 저지연 인프라를 필요로 합니다.

이 전환은 두 가지 구조적 압력으로 강화됩니다. 첫째, 대규모 클라우드 중단이 단일 제공업체 의존의 위험을 드러내어 많은 기업들이 이식성과 탄력성을 위해 설계하도록 촉구했습니다. 둘째, 지정학적 긴장과 주권 요건이 조직들이 데이터가 어디에 있고 워크로드가 어떻게 실행되는지에 대한 더 큰 통제를 추구하면서 클라우드 선택을 재형성하고 있습니다.

2026년까지 하이브리드 플랫폼이 주류가 될 것입니다. AI 워크로드는 엣지·프라이빗 클라우드·퍼블릭 클라우드 환경 사이를 원활하게 흐를 것입니다. Cloud 3.0은 클라우드가 단순한 IT 플랫폼에서 벗어나 AI(특히 에이전틱 AI)를 규모 있게 가능하게 하는 **분산 실행 레이어**가 되는 순간을 의미합니다.

**왜 중요한가**

Cloud 3.0은 탄력성을 높이지만 복잡성도 증가시킵니다. 차별화 요소는 더 이상 단일 플랫폼을 선택하는 것이 아니라 **상호운용성·이식성·지능적 워크로드 배치**를 마스터하는 것입니다. 기업에게 Cloud 3.0은 운영 모델을 중앙화된 클라우드 플랫폼 관리에서 지속적으로 진화하는 분산 컴퓨팅 패브릭의 오케스트레이션으로 변화시킵니다. 클라우드 제공업체들은 멀티벤더 유연성·소버린 배포 옵션·크로스클라우드 호환성·원활한 엣지-클라우드 통합을 유지해야 합니다. Cloud 3.0은 단순한 클라우드 채택의 또 다른 단계가 아니라, AI를 규모 있게 실행하고 지능형 기업 아키텍처의 다음 10년을 가능하게 하는 기반입니다.

**주목할 사항**

**AI 최적화 하이브리드 아키텍처**의 등장이 첫 번째 지표입니다. 파인튜닝이 통제된 프라이빗 클라우드에서 실행되고 추론은 지연 민감 애플리케이션을 위해 엣지에서 실행되는 프로젝트들이 AI 워크로드가 이미 단일 하이퍼스케일러 기본값 대신 환경 간을 유동적으로 이동하고 있음을 보여줍니다. 두 번째 신호는 **멀티클라우드 이식성 프레임워크**의 채택입니다. 기업들은 이제 비용이 아닌 탄력성과 주권을 위해 두 개 이상의 클라우드 제공업체에서 중요한 애플리케이션을 실행합니다. 또한 금융 서비스·공공 부문·헬스케어 조직들이 하이퍼스케일러 규모와 엄격한 로컬리티 통제를 결합한 **소버린 클라우드 리전 또는 소버린 오버레이** 파일럿을 이끌고 있습니다.

> *"클라우드는 새로운 단계에 진입하고 있습니다. AI 워크로드를 실행하고 에이전틱 시스템을 오케스트레이션하는 데 필요한 지능형 패브릭을 제공해야 하는 필요성에 의해 이끌리고 있습니다. 이 미래의 클라우드는 본질적으로 다면적입니다 — 멀티클라우드·하이브리드·엣지 환경이 단일 연속체로 운영됩니다."*
>
> **— Eric Fradet**, CTO and Head of Industrialization of Cloud Infrastructure Services, Capgemini

---

### Trend 5. 기술 주권의 국경 없는 역설

핵심 공급망을 둘러싼 긴장 고조, 데이터 및 클라우드 의존성에 대한 새로운 검토, AI 인프라 통제에 대한 우려 증가로 인해 **주권(sovereignty)이 전면에 다시 부상**했습니다. 코로나19 위기 이후 볼 수 없었던 수준으로 말입니다. 기업들과 정부들은 현대 경제가 완전히 통제하지 못하는 글로벌 기술 생태계에 얼마나 깊이 의존하는지 인식하고 있습니다.

동시에, "주권"의 정의는 아직 확정되지 않았습니다. 데이터 현지화를 의미하는가, 국내 클라우드 인프라 운영인가, 토착 칩 구축인가, 아니면 외국 AI 모델에 대한 의존 감소인가? 본질적으로 국경 없는 기술로 구축된 세상에서, 완전한 기술적 자율성은 환상일 수 있습니다. 현대 디지털 시스템은 반도체와 하이퍼스케일러 클라우드 플랫폼부터 오픈소스 프레임워크와 최첨단 AI 모델에 이르는 전 세계적으로 분산된 공급망에 의존합니다. 어떤 단일 조직도 혁신·규모·경쟁력을 잃지 않고 이 네트워크에서 현실적으로 분리될 수 없습니다.

이것이 새로운 현실로 이어집니다: **주권은 더 이상 고립이 아닌 탄력적 상호의존(resilient interdependence)**으로 정의됩니다.

대부분의 비즈니스 리더들에게 대화는 연속성과 통제로 이동했습니다. 제재·중단·지정학적 충격·비주권 행위자들의 결정에 의해 중요한 운영이 방해받지 않도록 보장하는 것. 주권은 탄력성의 문제가 됩니다: 외부 사건에 관계없이 데이터·인프라·인재에 대한 안전한 접근을 보장하는 능력.

이에 대응하여, 정부와 기업들은 완전한 디커플링이 아닌 의존성 리스크를 줄이는 신뢰할 수 있는 대안에 투자를 가속화하고 있습니다. 지역 클라우드 제공업체·소버린 클라우드 오퍼링·국내 칩 이니셔티브·개방형 AI 생태계가 모멘텀을 얻고 있습니다. 모든 주요 하이퍼스케일러들이 이제 2026년을 위한 소버린 및 규제 클라우드 오퍼링을 출시하거나 발표했습니다. 이것은 글로벌 플랫폼으로부터의 철수가 아닌 **설계에 의한 주권(sovereignty-by-design)**으로의 구조적 전환을 반영합니다.

이 사고방식은 새로운 아키텍처 원칙을 만들어냅니다. 조직들은 공급업체를 다양화하고, 멀티클라우드 및 멀티벤더 전략을 채택하며, 데이터 이식성을 유지하고, 규제 변화나 공급망 혼란을 운영 중단 없이 견딜 수 있도록 시스템을 재설계합니다. 주권이 클라우드 전략·데이터 관리·AI 배포에 내재된 설계 선택이 됩니다. 그 결과는 인프라가 개방적이고 상호 연결되어 있지만 더 이상 취약하지 않은 새로운 글로벌 지형입니다.

**왜 중요한가**

2026년에는 세계 주요 지역들이 반도체·데이터 인프라·클라우드·연결성·AI 모델 등 디지털 가치 사슬의 중요한 레이어에 대한 통제권 경쟁을 강화할 것입니다. 기업에게 이 전환은 심대한 영향을 미칩니다. 세이프가드 없는 의존은 더 이상 수용 불가합니다. 기술 전략은 이제 지정학적 변동성·공급망 리스크·규제 다양화를 고려해야 합니다. 궁극적으로 기술 주권은 더 이상 국경 뒤로 후퇴하는 것이 아닙니다. **상호의존을 통치하는 것**: 전 세계적으로 연결되어 있지만 통제 가능하고, 개방적이지만 노출되지 않으며, 확장 가능하지만 탄력적인 시스템을 구축하는 것입니다.

**주목할 사항**

가장 강력한 신호들이 클라우드·AI·컴퓨트·공급망 전반에 걸쳐 동시에 나타나고 있습니다. **소버린 클라우드 및 데이터 통제 아키텍처**의 급속한 채택이 하나의 명확한 지표입니다. 규제 부문이 글로벌 하이퍼스케일러 대신 소버린 환경 내에서 AI 추론 또는 중요 데이터 파이프라인을 실행하기 시작할 때, 주권은 이미 현실화되고 있습니다. **소버린 AI 생태계**의 부상도 두 번째 신호입니다. 정부와 산업이 지역에서 운영되는 파운데이션 모델·국가 훈련 데이터셋·섹터별 AI 기준선을 개발하고 있습니다. 그리고 **국내 컴퓨트 및 탄력적 공급망 프로그램**에서 세 번째 신호가 옵니다. 주권 리스크에 기반하여 워크로드를 할당하기 시작하는 순간, 그 전환은 명백합니다.

> *"기술 주권은 더 이상 정책 추상에 불과하지 않습니다. 그것은 국가뿐만 아니라 조직들에게도 전략적 관심사가 되었습니다. 대화는 고립의 환상에서 상호의존을 관리하고 전략적 자율성을 달성하는 실질적인 도전으로 이동하고 있습니다."*
>
> **— Nicolas Gaudillière**, CTO, Capgemini Invent France

---

### 2030년 이후 주목해야 할 이머징 시그널

다음 10년의 가장 중대한 기술적 전환 중 일부는 대중의 시야에서 멀리 펼쳐질 것입니다. 새로운 디지털 인터페이스나 소비자 플랫폼이 아닌, **원자 및 분자 규모에서 물리적 세계를 계산·모델링·엔지니어링하는 우리의 능력 발전**에서 나올 것입니다. 부식과 재료 열화에서 촉매 반응·배터리 안정성·반도체 신뢰성에 이르기까지, 가장 어려운 과학적·산업적 도전들은 고전적 방법으로는 근사할 수밖에 없는 양자 역학적 효과에 의해 지배됩니다.

고성능 컴퓨팅·AI 파운데이션 모델·점점 더 자동화되는 실험실들이 복잡한 물리적 시스템에 대한 훨씬 더 정밀한 탐색을 가능하게 하고 있습니다. 양자 하드웨어와 양자 영감 알고리즘의 진보가 시간이 지남에 따라 이 역량을 더욱 확장할 것으로 기대됩니다. 세 가지 이머징 시그널이 이 새로운 재료 혁신 물결이 어떻게 전개되는지를 보여줍니다.

**① 양자 거동으로 정의되는 재료 (Materials defined by quantum behavior)**

다음 재료 혁신 물결은 원자 수준에서 물질에 대한 더 깊은 이해에 의해 이끌릴 것입니다. 기술이 재료를 물리적 한계까지 밀어붙임에 따라, 성능·내구성·신뢰성은 고전적 엔지니어링 접근법이 포착하기 어려운 양자 규모 효과에 의해 점점 더 결정됩니다. 고성능 컴퓨팅·AI 기반 모델링·신흥 양자 기술의 결합은 과학자와 엔지니어들이 훨씬 더 높은 정확도로 재료 거동을 관찰·시뮬레이션·예측할 수 있게 합니다. 이것은 한편으로 첨단 배터리와 촉매에서 새로운 전자 및 초전도 재료에 이르기까지 획기적인 속성의 새로운 재료 클래스로 가는 문을 열어주고, 다른 한편으로 이러한 혁신들이 안정성·제조 가능성·장기 사용을 위해 엔지니어링될 수 있게 합니다.

**② 차세대 생분해성 (Next-generation biodegradability)**

두 번째 이머징 시그널은 재료가 원자 및 분자 수준에서 어떻게 열화되는지 이해하고 모델링하는 능력의 증가입니다. 생분해성은 전통적으로 경험적 테스트를 통해 평가되고 종종 내구성이나 일관성을 희생하여 달성되는 근사 속성으로 취급되었습니다. 고성능 컴퓨팅·AI 기반 모델·양자 컴퓨팅이 시간이 지남에 따라 재료가 환경과 상호작용하고 분해되는 방식을 지배하는 화학적·물리적 프로세스를 시뮬레이션할 수 있게 합니다. 장기적으로 이 역량은 지속 가능한 재료 설계를 근본적으로 재형성할 수 있습니다. 성능이 최적화된 후 생분해성을 추가하는 대신, 미래의 재료는 처음부터 성능·내구성·통제된 생애 말 거동의 균형을 맞추도록 엔지니어링될 수 있습니다. 포장재와 섬유에서 전자제품과 첨단 재료에 이르기까지, 규제 압력이 증가하는 산업들에 광범위한 영향을 미칩니다.

**③ 합성 재료 과학 (Synthetic material science)**

세 번째 프론티어는 재료를 발견하는 것에서 의도적으로 설계하는 것으로의 전환입니다. 자연에서 또는 시행착오를 통해 유용한 재료를 찾는 대신, 과학자들은 강도·전도성·열 저항성과 같은 원하는 속성을 정의하고 그 요건에 맞는 재료를 설계할 수 있게 됩니다. 재료들이 우연이 아닌 의도에 의해 형성된 엔지니어링 시스템을 닮아가기 시작합니다. AI 기반 모델들이 점점 더 자동화된 실험실과 결합하여, 연구자들이 방대한 수의 가능한 재료 조합을 탐색하고 원하는 결과에서 역방향으로 작업할 수 있게 합니다. 클라우드 기반 도구·공유 컴퓨팅 인프라·더 자율적인 설계 시스템들이 소수의 엘리트 실험실을 넘어 첨단 재료 엔지니어링을 확장하고 있습니다.

**이것이 의미하는 바**

이 시그널들은 기술 진보의 다음 단계가 첨단 컴퓨팅·화학·생물학의 수렴에 의해 이끌릴 것임을 보여줍니다. AI·고성능 컴퓨팅·실험실 자동화가 이미 물질이 탐색되고 엔지니어링되는 방식을 재형성하고 있으며, 양자 컴퓨팅은 성숙해감에 따라 이 역량을 더욱 확장할 것으로 기대됩니다. 이것이 다가오는 10년의 조용한 전환이 시작될 곳입니다: 인터페이스나 플랫폼의 수준이 아니라, 산업이 의존하는 기반 재료와 물리적 시스템에서 말입니다.

---

### 결론

2026년, 기술 환경은 AI의 성숙과 소프트웨어 전반으로의 통합, 클라우드의 멀티클라우드 생태계로의 진화, 지능형 운영의 부상으로 인해 큰 영향을 받을 것입니다. AI의 퍼베이시브한 영향력에 의해 이끌리는 이 트렌드들은 하이퍼 자동화를 가속화하고, 비즈니스 모델을 재정의하며, 적응적 기업을 가능하게 할 것을 약속합니다.

에이전틱 시스템과 기술 주권의 미묘한 균형 같은 신흥 우선순위들과 함께, 이러한 발전들은 **상호 연결되고 탄력적인 기술 프레임워크**를 향한 공유된 궤적을 강조합니다. 변혁적 변화는 여러 기술들이 복잡한 과제들을 해결하기 위해 원활하게 수렴할 때 발생한다는 것이 분명합니다.

이 트렌드들을 수용하는 것은 점점 더 유동적인 시장에서 가치를 추출하고, 성장을 지속하며, 경쟁 우위를 확보하는 데 필수적일 것입니다. 이 국경 없고 지능적인 미래를 활용하는 조직들은 2026년을 이끌 뿐만 아니라 앞으로 10년의 기반을 형성할 것입니다.

---

## 영어 원문

### Introduction

*Pascal Brier, Group Chief Innovation Officer, Member of the Group Executive Committee, Capgemini*

After several years of extraordinary acceleration across AI, cloud, data, and automation, 2026 marks a shift toward strengthening, upgrading or rebuilding the foundations that will support the next decade.

Across industries, leaders recognize that progress cannot rest on fragmented pilots or loosely connected digital initiatives. The era of experimental AI is giving way to the need for solid AI foundations: reliable data, clear governance, scalable architectures, and systems designed for safety, trust, and measurable outcomes. The organizations able to move from isolated models to integrated, enterprise-wide intelligence will be those that generate lasting value.

At the same time, the global environment is forcing companies to rethink resilience and business continuity at a much deeper level. Rising dependencies on critical technologies (from semiconductors and cloud services to AI models and compute infrastructure) have become strategic risk factors rather than purely technical choices. This is driving a dual movement: a renewed push for architectures that can withstand disruption, and a search for greater control over the layers of technology that matter most. Cloud strategies are evolving accordingly, with hybrid, multi-cloud, and sovereign options emerging not as exceptions but as mechanisms to secure continuity, reduce concentration risk, and safeguard data and operations. Sovereignty is part of this shift, but the underlying theme is broader: organizations are redesigning their foundations to remain open, scalable, and globally connected, while ensuring that no single dependency can compromise their ability to operate.

Our Top Tech Trends for 2026 reflect this shift toward structural rebuilding, pointing to a single message: technology leadership in 2026 is no longer about experimentation, but about constructing the durable foundations that will enable true value to be extracted from innovation.

As every major technological shift has shown, it is the strength of these foundations, not the novelty of individual tools, that determines who captures long-term advantage. This report aims to help business and technology leaders make the right strategic choices at a moment when those foundations are being rebuilt.

---

### Looking back to the top tech trends of the last two years

| 2025 | 2024 |
|------|------|
| **Generative AI:** From copilots to reasoning AI agents | **Generative AI:** Small will be the new big |
| **Cybersecurity:** New defenses, new threats | **Quantum technologies:** When cyber meets quantum |
| **AI-driven robotics:** Blurring the lines between humans and machines | **Semiconductors:** Moore's Law isn't dead, but it is changing |
| **Nuclear:** The surge of AI driving the clean tech agenda | **Batteries:** The power of new chemistry |
| **New-generation supply chains:** Agile, greener and AI-assisted | **Space tech:** Addressing the Earth's challenges from outer space |

---

### Trend 1. The year of truth for AI

After a period of unprecedented investment and experimentation, AI has become the defining technology of the decade. Yet the pace of investment has outstripped the speed at which organizations have been able to deploy it at scale and extract measurable value. Many enterprises now find themselves with sophisticated models, agents, and prototypes that remain unintegrated, under-utilized, or disconnected from real business outcomes. This gap has generated some skepticism and a sense of some form of AI hype.

Beneath the noise, however, something more consequential is taking shape. The structural foundations of AI are maturing. Organizations that have moved beyond pilots are already seeing tangible results, with early adopters reporting productivity gains of 7–18% across core digital and software operations. Crucially, these gains are not merely absorbed as efficiency: half of organizations reinvest the time saved into developing new features, while nearly as many channel it into workforce upskilling. This marks a shift from experimentation to value compounding.

At the same time, AI itself is evolving in form and function. Large models are becoming more modular, agents are moving from novelty tools to workflow orchestrators, and AI is shifting from peripheral experimentation to deeper integration within enterprise cores. Adoption reflects this transition. Today, roughly 46% of the software workforce uses generative AI tools; by 2026, that figure is expected to reach 85%, signaling a move from early adoption to default capability.

This is why 2026 emerges as the year of truth for AI. Short-term hype fades, but what remains is an ecosystem increasingly grounded in operational value, enterprise architecture, and sustained productivity. As with past technology waves, real growth begins once organizations recognize that value does not lie in isolated use cases but in enterprise-wide systems that evolve and scale over time.

Reaching that future requires discipline. Organizations must confront their true AI readiness, starting with data foundations and infrastructure. The agentic wave is accelerating, but not all agents are built to scale; hastily assembled "toy agents" risk renewing disappointment. Differentiation no longer comes from the models themselves, which are rapidly commoditizing, but from architecture, integration, orchestration, and the ability to turn AI into durable, compounding business value.

**Why it matters**

After years of hype and fragmented pilots, AI can no longer be innovation theater. Investment has outpaced value delivery, and 2026 is the moment when organizations must move from proof-of-concept to proof-of-impact. The next wave of AI is not about specific tools or model releases; it is about embedding intelligence into the fabric of operations, processes, and society (and making it work for everyone). Leaders who succeed will build the capabilities, governance, and human-AI chemistry required to deliver measurable outcomes at scale, while laying the foundations for the larger-scale transformation that will follow.

**What to look out for**

Organizations increasingly turn from experimental AI agents to **production-grade agentic systems** built to operate within real enterprise architectures. This shift favors platforms that integrate directly with existing data pipelines, identity layers, workflow engines, and business applications. Early proofs of concept give way to robust orchestration frameworks that coordinate multiple specialized agents, each with defined roles, evaluation loops, and governance controls. Momentum also builds around **modular and domain-specific models.**

As general-purpose LLMs commoditize, enterprises prioritize smaller, fine-tuned models tailored to finance, healthcare, retail, or industrial operations. These models rely on improved retrieval, vector databases, and continuous fine-tuning pipelines, giving organizations tighter control over accuracy, provenance, and performance—especially in regulated environments.

At the same time, the pressure to demonstrate concrete ROI accelerates investment in **AI observability, evaluation, and value measurement.** Companies establish internal evaluation suites to test model behavior, monitor agent decisions, and assess reliability against business outcomes. Dedicated "AI value offices" or governance teams emerge to oversee performance at scale, drawing on telemetry, productivity insights, and financial impact.

Finally, the rapid adoption of **AI-augmented engineering and operations** signals that intelligence is becoming embedded across the software development lifecycle and core business workflows. Code generation pipelines, automated testing agents, self-optimizing data workflows, and AI copilots for operations move from experimentation to standard practice. These shifts reinforce the broader transformation described across this report: AI is no longer an add-on—it is becoming a structural capability of the modern technology stack.

> *"Generative AI has attracted unprecedented levels of investment and attention. As we move into 2026, the conversation is shifting decisively toward value creation—moving beyond experimentation to measurable business impact."*
>
> **— Mark Roberts**, Head of AI Futures Lab, Capgemini

---

### Trend 2. AI is eating software

For more than two decades, software has powered digital transformation. After the era when "software ate the world," we now enter a new phase where "AI is beginning to eat software itself". What started as isolated AI tools (code completion, automated testing, prompt-based generation) has evolved into a fundamentally new software development paradigm, where humans and AI continuously conceptualize, design, build and refactor systems together.

AI-native development is no longer experimental. Large enterprises, in particular, are moving first: three-quarters of organizations with more than $20 billion in annual revenue have already piloted or scaled generative AI for software engineering. Enterprises are moving beyond AI-assisted coding to fully autonomous software development ecosystems, deploying self-directed testing frameworks, intelligent code-generation agents, continuous auto-refactoring engines, and agentic build-and-release systems that collaborate, learn, and optimize with human interventions. The impact is transformative: delivery cycles accelerate, technical debt is resolved earlier, and developers shift from manually writing code to expressing intent and orchestrating intelligent pipelines.

In 2026, this shift becomes structural. Developers increasingly describe outcomes in natural language or high-level specifications. AI generates the design, implements it, tests it, secures it, optimizes it, integrates it and continuously refactors it as requirements evolve. A new model emerges where AI-assembled components adapt in near real time and software becomes an evolving service rather than a static asset.

At this point, the traditional concept of an application will begin to fade. Users express goals, and AI agents dynamically assemble, run, and maintain the underlying logic. The visible app layer shrinks; behind it, composable AI services evolve autonomously, self-testing, self-healing, and updating themselves as new conditions arise.

This transition brings enormous opportunity. It also demands a fundamental unlearning of old software habits. AI-generated code is powerful but not infallible, making governance, validation, and architectural oversight more critical than ever. The skills that once differentiated developers (package configuration, front-end coding, manual quality assurance) lose importance. The new currency of expertise becomes systems thinking, AI orchestration, architecture, and the ability to manage complex autonomous toolchains.

**Why it matters**

This shift is not only technological; it is strategic. As enterprises reach the limits of traditional DevOps, AI-native development introduces a new pathway to speed and agility. Agentic pipelines can generate, test, and refactor software continuously, shrinking quality assurance cycles and enabling near-real-time adaptation. This is a foundational element in building AI-native businesses. When software evolves automatically rather than through manual releases, systems become adaptive, allowing organizations to respond to market changes far faster than static architecture currently allows.

At the same time, AI-generated software opens new options for digital sovereignty. By lowering the cost and effort required to design, maintain, and evolve software, AI-native development reduces the economic barriers that have historically pushed organizations toward large, standardized SaaS platforms. This makes it viable—where strategic control, regulatory constraints, or data locality matter—to replace monolithic SaaS with tailored systems whose codebase, data flows, and evolution remain under direct organizational control and aligned with strategic autonomy goals.

Finally, this shift frees human talent for higher-value work. Automation of routine software development lifecycle tasks redirects engineers' focus toward architecture, product logic, and governance, provided they are able to build on traditional practices and master new AI-driven toolchains.

**What to look out for**

Enterprises begin deploying **agentic build systems** that generate, test, secure, and refactor code continuously. These systems go far beyond today's code assistants and act as full orchestration engines, translating intent into production-ready code and maintaining it as requirements evolve. Early adopters already use them to reduce technical debt and compress release cycles dramatically.

We also see rapid advances in **autonomous quality assurance and reliability pipelines,** where test generation, regression detection, vulnerability scanning, and dependency management are handled end-to-end by AI. As manual QA becomes impractical at the speed AI enables, these reliability pipelines form the backbone of trustworthy AI-generated software.

Another signal of this shift is the rise of **dynamic, composable services** assembled automatically by AI. Instead of treating applications as fixed assets, enterprises move toward adaptive Service-as-Software models where components are assembled, optimized, and updated in near real time.

Finally, **AI-governed development environments** become essential to manage this transition. Evaluation frameworks, behavioral monitoring, lineage tracking, and architectural guardrails mature to ensure autonomous toolchains remain reliable, controllable, and aligned with enterprise requirements.

> *"The fundamentals of software creation are being rewritten. We are entering an era of AI powered software rebuild, where competitive advantage hinges on deep control over costs, sovereignty, cybersecurity, and data privacy."*
>
> **— Sudhir Pai**, Deputy Group CTO, Capgemini

---

### Trend 3. The rise of intelligent ops

After years of enterprise resource planning (ERP) modernization, cloud migration, and process automation, enterprises are entering a new era—one where their operational core becomes intelligent by design. AI is no longer bolted on; it is enabling the complete redesign of business processes, transforming them from linear, predefined sequences into living systems capable of continuous optimization.

In 2025, the use of AI agents in operations more than doubled to 21% (up from 10% in 2024). The speed of AI adoption, the explosion of real-time data, and the emergence of autonomous agents are driving the rise of intelligent operations. At the center of this shift sits a new kind of enterprise core: dynamic, modular, and powered by data, where platforms, AI agents and humans collaborate in real time to deliver efficiencies and business value while maintaining operations that are agile and resilient. By 2028, Gartner expects close to 40% of enterprise workflows to be automated or augmented by AI agents, underscoring how deeply intelligence is moving into day-to-day operations.

Three structural shifts define this transition. First, intelligent processes are being re-imagined to make them AI ready. The AI first processes are hyper automated using a blend of technologies spanning across RPA, Gen AI and agentic AI. Together, these technologies give processes the ability to interpret signals, adapt workflows, and trigger actions in an intelligent way. This direction is already explicit in executive intent: 82% of organizations plan to integrate AI agents by 2027, and 85% of executives expect them to autonomously handle one or more business processes within the next three to five years.

Second, organizations are moving beyond isolated process optimization to orchestrating value chains. This holistic approach breaks down silos, eliminates friction at process handoffs, and creates seamless, end-to-end operations that connect functions into a unified value stream.

Third, the role of people evolves toward human–AI co-steering: AI proposes and executes, while humans supervise, validate outcomes, and apply judgment. This partnership blends machine speed with human insight to accelerate execution while safeguarding safety, ethical guardrails and trust.

**Why it matters**

Operations are the heartbeat of every organization—the fundamental activities that keep a business running. They are data-rich, repetitive, and deeply tied to business outcomes, making them one of the most powerful use cases for AI.

In 2026, leaders face a breaking point: they must move beyond pilots and isolated automation to match the pace of change. Intelligent operations offer a scalable path to transform the core of the organization and unlock greater value. The payoff is significant: continuously adapting operations, reduced friction, and a digital core that evolves with the business rather than slowing it down. Intelligent operations ensure enterprises not only run better, but allow them to continuously reinvent themselves, marking the moment when AI becomes a true co-operator.

In addition to efficiency, this shift is about redefining how businesses create business value. Intelligent operations unlock growth by enabling faster innovation, improving customer experiences, and building resilience into every process. When AI becomes embedded in the operational core, enterprises gain the agility to anticipate change, adapt in real time, and turn disruption into advantage.

**What to look out for**

In 2025, agentic AI projects surged by 48%, driven largely by experimentation through pilot initiatives. In 2026, expect more and more organizations to move from pilots to first production levels, with the focus evolving from cost savings to value creation. One of the clearest indicators is the growing intent to replace legacy workflows outright with AI-enabled ones. **This isn't about layering automation on top of old processes. It's about redesigning operations from the ground up,** with generative AI, RPA, analytics, and AI agents working hand in hand.

A second tell is the rise of **connected operations** that span entire value chains. Projects in which supply chain, finance, procurement, and customer operations operate as one orchestrated system (with AI coordinating handoffs and resolving issues across functions) show that organizations are moving beyond isolated KPIs and beginning to treat processes as integrated flows.

Finally, another clear signal is **human–AI co-steering** in operational command centers becoming more formalized and strategic. Instead of dashboards that only report metrics, teams start to work in environments where AI suggests actions, executes routine tasks, and escalates only when human judgment is required. Pilots already show AI handling month-end close steps and vendor risk checks which frees up humans to focus on exceptions and strategic decisions that drive value.

Together, these projects demonstrate that operations are shifting from fragmented workflows to adaptive, AI-operated systems. The real story beyond cost reduction, is the ability to unlock new value streams and transform operations into a true growth engine.

> *"Operations are no longer static systems optimized once and maintained over time. They are becoming intelligent, adaptive cores—where AI is embedded into processes and humans co-steer systems that learn and evolve continuously."*
>
> **— Manuel Sevilla**, CTInO, Capgemini Business Services

---

### Trend 4. Cloud 3.0 – all flavors of cloud

Cloud is entering its next evolution. After a decade focused on migration, modernization, and cost optimization, it is becoming the execution backbone for AI and AI-assisted applications. This shift is reflected in scale: public cloud spending is expected to almost double from $723 billion in 2025 to $1.47 trillion by 2029, with generative AI projected to account for 10–15% of that spend by the end of the decade. Cloud value is no longer defined by elasticity alone, but by its ability to sustain AI-intensive, always-on workloads.

Yet AI cannot scale on classical public cloud architectures alone. The need to fine-tune models on proprietary data, control data sensitivity, meet regulatory constraints, and deliver low-latency inference is pushing organizations toward hybrid, private, multi-cloud, and sovereign cloud architectures, not as exceptions but as the new norm. Agentic systems, in particular, require scalable, distributed, low-latency infrastructure where cloud and edge operate as a single intelligent fabric.

This shift is reinforced by two structural pressures. First, large-scale cloud outages have exposed the risk of single-provider dependence, prompting many enterprises to design for portability and resilience. Second, geopolitical tensions and sovereignty requirements are reshaping cloud choices as organizations seek greater control over where data resides and how workloads are executed.

By 2026, hybrid platforms will become mainstream. AI workloads will flow seamlessly between edge, private cloud, and public cloud environments. Organizations will redesign their architectures for resilience, interoperability, and strategic autonomy. Cloud 3.0 marks the moment when cloud stops being only an IT platform and becomes the distributed execution layer that makes AI (especially agentic AI) possible at scale.

**Why it matters**

Cloud 3.0 increases resilience, but also complexity. As AI adoption accelerates, enterprises must operate confidently across diverse environments, providers, and jurisdictions. The differentiator is no longer choosing a single platform but mastering interoperability, portability, and intelligent workload placement.

This shift also raises expectations for cloud providers. They will need to remain agile regarding multi-vendor flexibility, sovereign deployment options, cross-cloud compatibility, and seamless edge-to-cloud integration, all while supporting the performance demands of generative AI and agentic workloads. Providers able to deliver openness and resilience will shape the next phase of the market.

For enterprises, Cloud 3.0 changes the operating model from managing a centralized cloud platform to orchestrating a continuously evolving, distributed computing fabric. New skills, governance, and product thinking are required to orchestrate distributed infrastructures, ensure continuity, and deploy AI workloads safely across clouds and edges. Those who adapt turn cloud from a cost center into a strategic enabler of speed, autonomy, and competitive advantage.

Cloud 3.0 is therefore not just another stage of cloud adoption: it becomes the foundation for running AI at scale, building operational resilience, and enabling the next decade of intelligent enterprise architectures.

**What to look out for**

Several concrete developments signal that Cloud 3.0 is taking hold in 2026. One early indicator is the emergence of **AI-optimized hybrid architectures,** where enterprises deliberately split workloads across private, public, and edge environments. Projects where fine-tuning runs in controlled private clouds while inference executes at the edge for latency-sensitive applications show that AI workloads are already moving fluidly across environments instead of defaulting to a single hyperscaler—a clear sign that Cloud 3.0 is underway.

A second tell is the adoption of **multi-cloud portability frameworks.** Enterprises now run critical applications on two or more cloud providers, not for cost reasons, but for resilience and sovereignty. Containerized AI services, cloud-agnostic data layers, and replicated inference stacks deployed simultaneously across providers become visible proof points, emerging in response to recent outages and geopolitical risk.

Another signal is the **deployment of sovereign cloud regions or sovereign overlays** for sensitive workloads. Financial services, public sector, and healthcare organizations are leading pilots that combine hyperscaler scale with strict locality controls, audited administration, and independent cryptographic governance.

Together, these projects show the shift from cloud as a destination to cloud as a distributed, intelligent substrate for running AI at scale. These are the tells that Cloud 3.0 has entered the operational mainstream.

> *"Cloud is entering a new phase, driven by the need to provide the intelligent fabric required to run AI workloads and orchestrate agentic systems. This future cloud is inherently multi-faceted, spanning multi-cloud, hybrid, and edge environments operating as a single continuum."*
>
> **— Eric Fradet**, CTO and Head of Industrialization of Cloud Infrastructure Services, Capgemini

---

### Trend 5. The borderless paradox of technological sovereignty

Escalating tensions around critical supply chains, renewed scrutiny of data and cloud dependencies, and growing concern over AI infrastructure control have pushed sovereignty back to the forefront—at levels not seen since the COVID-19 crisis. Enterprises like governments are recognizing how deeply modern economies rely on global technology ecosystems they do not fully control.

At the same time, the definition of "sovereignty" is far from settled. Does it mean localizing data, operating domestic cloud infrastructure, building indigenous chips, mandating open-source alternatives, or reducing dependence on foreign AI models? And to what extent is any of this achievable? In a world built on inherently borderless technologies, complete technological autonomy may appear to be an illusion. Modern digital systems depend on globally distributed supply chains—from semiconductors and hyperscaler cloud platforms to open-source frameworks and frontier AI models. No single organization can realistically detach from this web without losing innovation, scale, or competitiveness.

This leads to a new reality: sovereignty is no longer defined by isolation, but by **resilient interdependence.**

For most business leaders, the conversation has shifted toward continuity and control: ensuring that critical operations cannot be disrupted by sanctions, outages, geopolitical shocks, or decisions made by non-sovereign actors. Sovereignty becomes a question of resilience: the ability to guarantee secure access to data, infrastructure, and talent regardless of external events.

In response, governments and enterprises are accelerating investment not in full decoupling, but in credible alternatives that reduce dependency risks. Regional cloud providers, sovereign cloud offerings, domestic chip initiatives, and open-AI ecosystems are gaining momentum. All major hyperscalers have now launched or announced sovereign and regulated cloud offerings for 2026, reflecting a structural shift toward sovereignty-by-design rather than withdrawal from global platforms. These options do not replace global platforms, but they strengthen negotiation power, increase strategic flexibility, and reduce operational fragility.

This mindset results in new architectural principles. Organizations diversify suppliers, adopt multi-cloud and multi-vendor strategies, maintain data portability, and redesign systems so they can withstand regulatory shifts or supply-chain disruptions without interrupting operations. Sovereignty becomes a design choice, embedded into cloud strategy, data management, and AI deployment. The outcome is a new global landscape where infrastructures remain open and interconnected but no longer fragile.

**Why it matters**

In 2026, the world's major regions will intensify their race for control over the critical layers of the digital value chain: semiconductors, data infrastructure, cloud, connectivity, and AI models. At the same time, hyperscalers and large cloud providers are launching sovereign and region-specific offerings, reshaping how enterprises think about trust, compliance, and operational continuity.

For companies, this shift has profound implications. Dependency without safeguards is no longer acceptable. Technology strategies must now account for geopolitical volatility, supply-chain risk, and regulatory divergence. Architectures must be designed for resilience—ensuring portability across providers, continuity during outages, and flexibility to adapt to new localization rules.

Ultimately, technology sovereignty is no longer about retreating behind borders. It is about governing interdependence: building systems that remain globally connected, but controllable; open, but not exposed; scalable, but resilient. This new approach will define how organizations build trust, manage risk, and ensure long-term competitiveness in the decade ahead.

**What to look out for**

The strongest signals that technology sovereignty is becoming real in 2026 come from concrete projects appearing simultaneously across cloud, AI, compute, and supply chains. One clear indicator is the rapid adoption of **sovereign cloud and data-control architectures.** Enterprises are moving sensitive workloads to region-governed cloud zones or sovereign overlays, where administration, encryption, and data locality remain under jurisdictional control. When regulated sectors begin running AI inference or critical data pipelines inside sovereign environments rather than defaulting to global hyperscalers, sovereignty is already materializing.

A second tell is the rise of **sovereign AI ecosystems.** Governments and industries are developing locally governed foundational models, national training datasets, and sector-specific AI baselines. These initiatives ensure that high-risk workloads—public services, healthcare, finance, and defense—do not depend solely on foreign black-box models. The moment enterprises start adopting "trusted AI stacks" with clear provenance, auditability, and jurisdictional guarantees, sovereignty moves from policy aspiration to operational practice.

A third signal comes from **domestic compute and resilient supply-chain programs.** Nations and industries are investing in chip fabrication, advanced packaging capacity, sovereign GPU clusters, and diversification of hardware suppliers. Enterprises increasingly design for multi-cloud continuity and hardware portability to protect against sanctions, outages, or geopolitical shock. When organizations begin allocating workloads or procurement choices based on sovereignty risk, the shift is unmistakable.

Together, these developments show sovereignty expanding across technology domains. A move from dependency to managed interdependence will become a defining strategic posture for enterprises in 2026.

> *"Technology sovereignty is no longer a policy abstraction. It has become a strategic concern not only for nations, but for organizations as well. The conversation is shifting from the illusion of isolation to the practical challenge of managing interdependence and achieving strategic autonomy."*
>
> **— Nicolas Gaudillière**, CTO, Capgemini Invent France

---

### Emerging signals to watch by 2030 and beyond

Some of the most consequential technological shifts of the next decade will unfold far from the public eye. They will not originate from new digital interfaces or consumer platforms, but from advances in our ability to compute, model, and engineer the physical world at the atomic and molecular scale. Many of the hardest scientific and industrial challenges—from corrosion and material degradation to catalytic reactions, battery stability, and semiconductor reliability—are governed by quantum-mechanical effects that classical methods can only approximate.

A new generation of capabilities is now changing this equation. High-performance computing, AI and foundation models for science, and increasingly automated laboratories are already enabling far more precise exploration of complex physical systems. Progress in quantum hardware and quantum-inspired algorithms is expected to further extend these capabilities over time. Together, these technologies are shifting material innovation away from empirical trial-and-error toward modelling and design grounded in first principles.

These advances matter because they reshape the foundations of energy, infrastructure, manufacturing, sustainability, and health. Taken together, three emerging signals illustrate how this new wave of materials innovation is unfolding: materials are increasingly defined by their quantum behavior; their design processes now span the full lifecycle, from manufacturability and performance to degradation and recyclability; and they are progressively engineered for specific functions rather than discovered through empirical trial and error.

**Materials defined by quantum behavior**

The next wave of materials innovation will be driven by a deeper understanding of matter at the atomic scale. As technologies push materials to their physical limits, performance, durability, and reliability are increasingly determined by quantum-scale effects that classical engineering approaches struggle to capture. Many long-standing industrial challenges—such as corrosion, degradation, and material fatigue under real operating conditions—originate at this level.

Advances in computation are changing this dynamic. The combination of high-performance computing, AI-driven modelling, and emerging quantum techniques is allowing scientists and engineers to observe, simulate, and predict material behavior with far greater accuracy. The impact is twofold. On one hand, this opens the door to new classes of materials with breakthrough properties, from advanced batteries and catalysts to novel electronic and superconducting materials. On the other, it enables these innovations to be engineered for stability, manufacturability, and long-term use.

**Next-generation biodegradability**

A second emerging signal is the growing ability to understand and model how materials degrade at the atomic and molecular level. Biodegradability has traditionally been treated as an approximate property, assessed through empirical testing and often achieved at the expense of durability or consistency. As a result, material degradation has remained difficult to predict, control, or design with precision.

Advances in computation are beginning to change this. High-performance computing, AI-driven models, and, over time, quantum computing make it possible to simulate the chemical and physical processes that govern how materials interact with their environment and break down over time. This deeper understanding allows engineers to move beyond trial-and-error approaches and start designing degradation pathways intentionally, based on how materials behave at the atomic scale.

Over the long term, this capability could fundamentally reshape sustainable materials design. Instead of retrofitting biodegradability after performance has been optimized, future materials can be engineered from the outset to balance performance, durability, and controlled end-of-life behavior. This shift has far-reaching implications for industries facing increasing sustainability and regulatory pressures, from packaging and textiles to electronics and advanced materials.

**Synthetic material science**

The third frontier is the shift from discovering materials to deliberately designing them. Instead of searching for useful materials in nature or through trial and error, scientists are increasingly able to define the properties they want—such as strength, conductivity, or resistance to heat—and design materials to match those requirements. Materials begin to resemble engineered systems, shaped by intent rather than chance.

This shift is enabled by advances in computation and automation. AI-driven models, combined with increasingly automated laboratories, allow researchers to explore vast numbers of possible material combinations and work backward from desired outcomes. What once required years of experimentation can increasingly be achieved through continuous, data-driven design loops that rapidly test, refine, and validate new material candidates.

Over time, these capabilities are becoming more accessible. Cloud-based tools, shared computational infrastructure, and more autonomous design systems are lowering barriers to entry, extending advanced materials engineering beyond a small number of elite laboratories. The result is a broad expansion of material innovation, with implications across mobility, energy, infrastructure, electronics, and healthcare.

**What does this mean?**

Taken together, these signals show that the next phase of technological progress will be driven by the convergence of advanced computation, chemistry, and biology. AI, high-performance computing, and laboratory automation are already reshaping how matter can be explored and engineered, while quantum computing is expected to further extend these capabilities as it matures. In parallel, advances in molecular engineering and synthetic biology are translating digital insight into physical materials with properties designed for specific functions and constraints.

This is where the quiet shifts of the coming decade will originate: not at the level of interfaces or platforms, but in the underlying materials and physical systems on which industries depend. Organizations that recognize this convergence will be better positioned to anticipate long-term technological change, manage emerging resources and sovereignty constraints, and build durable advantages in a world where control over matter itself is becoming a strategic capability.

---

### Concluding remarks

In 2026, the technology landscape will be impacted by the maturation of AI and its integration across software, the evolution of cloud into multi-cloud ecosystems, and the rise of intelligent operations. These trends, driven by AI's pervasive influence, promise to accelerate hyper automation, redefine business models, and enable adaptive enterprises. Alongside emerging priorities such as agentic systems and the delicate balance of tech sovereignty, these developments underscore a shared trajectory toward interconnected and resilient technology frameworks. It's clear that transformative change occurs when multiple technologies converge seamlessly to address complex challenges.

Embracing these trends will be essential for extracting value, sustaining growth and securing a competitive edge in an increasingly fluid market. Organizations that harness this borderless, intelligent future will not only lead in 2026 but also shape the foundation for the decade ahead.

---

## 표현 정리

<iframe
  src="/assets/html/voca_capgemini-top-tech-trends-2026.html"
  style="width:100%; height:740px; border:none; border-radius:12px; box-shadow: 0 2px 20px rgba(0,0,0,0.12);"
  title="Capgemini Top Tech Trends 2026 — 어휘 학습 카드">
</iframe>

<div style="text-align:right; margin-top:8px;">
  <a href="/assets/html/voca_capgemini-top-tech-trends-2026.html" target="_blank" class="btn btn--inverse btn--small">새 탭에서 열기 ↗</a>
</div>
